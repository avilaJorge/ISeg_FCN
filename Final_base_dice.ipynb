{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "Final_base_dice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxRpsKtA0kz8",
        "colab_type": "text"
      },
      "source": [
        "Below lines are only for downloading dataset and checking resources."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMezdmzaY64P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0yC5X9HRpQfl",
        "outputId": "e94084e6-254b-4b69-c5c2-7efad4dd60d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=avilaJorge&password=C323781C&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-15 06:00:14--  https://www.cityscapes-dataset.com/login/\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cityscapes-dataset.com/downloads/ [following]\n",
            "--2020-02-15 06:00:17--  https://www.cityscapes-dataset.com/downloads/\n",
            "Reusing existing connection to www.cityscapes-dataset.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html.2’\n",
            "\n",
            "index.html.2            [   <=>              ]  41.56K  75.6KB/s    in 0.5s    \n",
            "\n",
            "2020-02-15 06:00:19 (75.6 KB/s) - ‘index.html.2’ saved [42561]\n",
            "\n",
            "--2020-02-15 06:00:20--  https://www.cityscapes-dataset.com/file-handling/?packageID=1\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252567705 (241M) [application/octet-stream]\n",
            "Saving to: ‘gtFine_trainvaltest.zip’\n",
            "\n",
            "gtFine_trainvaltest 100%[===================>] 240.87M  10.8MB/s    in 24s     \n",
            "\n",
            "2020-02-15 06:00:46 (10.0 MB/s) - ‘gtFine_trainvaltest.zip’ saved [252567705/252567705]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edeW64UMmjcA",
        "colab_type": "code",
        "outputId": "56682871-f288-4684-ff52-9288c57f1fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=avilaJorge&password=C323781C&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-15 06:01:26--  https://www.cityscapes-dataset.com/login/\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cityscapes-dataset.com/downloads/ [following]\n",
            "--2020-02-15 06:01:28--  https://www.cityscapes-dataset.com/downloads/\n",
            "Reusing existing connection to www.cityscapes-dataset.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html.3’\n",
            "\n",
            "index.html.3            [   <=>              ]  41.56K  77.2KB/s    in 0.5s    \n",
            "\n",
            "2020-02-15 06:01:30 (77.2 KB/s) - ‘index.html.3’ saved [42561]\n",
            "\n",
            "--2020-02-15 06:01:32--  https://www.cityscapes-dataset.com/file-handling/?packageID=3\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11592327197 (11G) [application/octet-stream]\n",
            "Saving to: ‘leftImg8bit_trainvaltest.zip’\n",
            "\n",
            "leftImg8bit_trainva 100%[===================>]  10.80G  10.8MB/s    in 17m 6s  \n",
            "\n",
            "2020-02-15 06:18:41 (10.8 MB/s) - ‘leftImg8bit_trainvaltest.zip’ saved [11592327197/11592327197]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZINW93N3pmYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('leftImg8bit_trainvaltest.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./Data')\n",
        "with zipfile.ZipFile('gtFine_trainvaltest.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./Data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XATSYgcx_oCD",
        "colab": {}
      },
      "source": [
        "# !cp -nR ./datasets/. ./drive/My\\ Drive/CSE253/datasets\n",
        "!mv ./Data ./cityscapes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_6kHDlahsfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir datasets\n",
        "!mv ./cityscapes ./datasets/cityscapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T779pnAShzZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv ./datasets /content/drive/My\\ Drive/CSE253/PA3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNQedZ0zsGnL",
        "colab_type": "code",
        "outputId": "0247fb30-2713-493f-b749-457d14605e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Feb 15 18:32:13 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n",
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 2\n",
            "initial apicid\t: 2\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 2\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 3\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 3\n",
            "initial apicid\t: 3\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3pEoUK0ZF70",
        "colab_type": "code",
        "outputId": "0ca6acbb-531c-487f-d819-cf02f1dea67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "!mv ./test /content/drive/My\\ Drive/CSE253/PA3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat './test': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26MRFDwIGdwg",
        "colab_type": "code",
        "outputId": "e4a446f6-1467-4f58-8383-1e109d819145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "# Import packages\n",
        "import os,sys,humanize,psutil,GPUtil\n",
        "\n",
        "# Define function\n",
        "def mem_report():\n",
        "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
        "  \n",
        "  GPUs = GPUtil.getGPUs()\n",
        "  for i, gpu in enumerate(GPUs):\n",
        "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "    \n",
        "# Execute function\n",
        "mem_report()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-596db65e9205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhumanize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsutil\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGPUtil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmem_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CPU RAM Free: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhumanize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaturalsize\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'GPUtil'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwp1KbnX0uTq",
        "colab_type": "text"
      },
      "source": [
        "------------- Code Starts Here -----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U6GPrYjHErx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import utils\n",
        "from dataloader import *\n",
        "from utils import *\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import time\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "1-DLo_fHAs4W",
        "colab_type": "code",
        "outputId": "1f68a827-d5f6-46bc-e692-b4a724dd1a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "def print_GPU_stats():\n",
        "    print(\"total GPU Mem: \", torch.cuda.get_device_properties(device).total_memory)\n",
        "    print(\"total GPU Cached: \", torch.cuda.memory_cached(device))\n",
        "    print(\"total GPU Allocated: \", torch.cuda.memory_allocated(device))\n",
        "    print(\"Available GB: \", (torch.cuda.get_device_properties(device).total_memory - torch.cuda.memory_allocated(device))/(10**9))\n",
        "print_GPU_stats()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "total GPU Mem:  17071734784\n",
            "total GPU Cached:  0\n",
            "total GPU Allocated:  0\n",
            "Available GB:  17.071734784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPkHApt7SnCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW1tM2upAs4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change name to FCN to use this model instead I think\n",
        "\n",
        "class FCN_bak(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_class):\n",
        "        super(FCN_bak, self).__init__()\n",
        "        self.n_class = n_class\n",
        "        self.conv1   = nn.Conv2d(3, 32, kernel_size=(3,5), stride=(2,4), padding=1, dilation=1)\n",
        "        self.bnd1    = nn.BatchNorm2d(32)\n",
        "        self.conv2   = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, dilation=1)\n",
        "        self.bnd2    = nn.BatchNorm2d(64)\n",
        "        self.conv3   = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, dilation=1)\n",
        "        self.bnd3    = nn.BatchNorm2d(128)\n",
        "        self.conv4   = nn.Conv2d(128,256, kernel_size=3, stride=2, padding=1, dilation=1)\n",
        "        self.bnd4    = nn.BatchNorm2d(256)\n",
        "        self.conv5   = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1, dilation=1)\n",
        "        self.bnd5    = nn.BatchNorm2d(512)\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(256)\n",
        "        self.deconv2 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(128)\n",
        "        self.deconv3 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(64)\n",
        "        self.deconv4 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(32)\n",
        "        self.deconv5  = nn.ConvTranspose2d(32, 3, kernel_size=(3, 5), stride=(2,4), padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5= nn.BatchNorm2d(3)\n",
        "        self.classifier = nn.Conv2d(3,n_class, kernel_size=1, stride=1, padding=0, dilation=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        pool = nn.MaxPool2d(2, stride=2,return_indices = True)\n",
        "        unpool = nn.MaxUnpool2d(2, stride=2)\n",
        "        \n",
        "        x1, indice1 = pool(self.relu(self.conv1(x)))\n",
        "        x2, indice2 = pool(self.relu(self.conv2(self.bnd1(x1))))\n",
        "        x3, indice3 = pool(self.relu(self.conv3(self.bnd2(x2))))\n",
        "        x4, indice4 = pool(self.relu(self.conv4(self.bnd3(x3))))\n",
        "        x5, indice5 = pool(self.relu(self.conv5(self.bnd4(x4))))\n",
        "        \n",
        "        z1 = self.deconv1(self.bnd5(self.relu(unpool((x5), indice5))))\n",
        "        z2 = self.deconv2(self.bn1(self.relu(unpool((z1), indice4))))\n",
        "        z3 = self.deconv3(self.bn2(self.relu(unpool((z2), indice3))))\n",
        "        z4 = self.deconv4(self.bn3(self.relu(unpool((z3), indice2))))\n",
        "        z5 = self.deconv5(self.bn4(self.relu(unpool((z4), indice1))))\n",
        "        \n",
        "        out_decoder = self.classifier(self.bn5(z5))                  \n",
        "\n",
        "        return out_decoder  # size=(N, n_class, x.H/1, x.W/1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujBPdFdaqfzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageBase(object):\n",
        "    \n",
        "    def __init__(self, value=0):\n",
        "        self.value = float(value) if value is not None else None\n",
        "       \n",
        "    def __str__(self):\n",
        "        return str(round(self.value, 4))\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.value\n",
        "    \n",
        "    def __format__(self, fmt):\n",
        "        return self.value.__format__(fmt)\n",
        "    \n",
        "    def __float__(self):\n",
        "        return self.value\n",
        "    \n",
        "\n",
        "class RunningAverage(AverageBase):\n",
        "    \"\"\"\n",
        "    Keeps track of a cumulative moving average (CMA).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, value=0, count=0):\n",
        "        super(RunningAverage, self).__init__(value)\n",
        "        self.count = count\n",
        "        \n",
        "    def update(self, value):\n",
        "        self.value = (self.value * self.count + float(value))\n",
        "        self.count += 1\n",
        "        self.value /= self.count\n",
        "        return self.value\n",
        "\n",
        "\n",
        "class MovingAverage(AverageBase):\n",
        "    \"\"\"\n",
        "    An exponentially decaying moving average (EMA).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, alpha=0.99):\n",
        "        super(MovingAverage, self).__init__(None)\n",
        "        self.alpha = alpha\n",
        "        \n",
        "    def update(self, value):\n",
        "        if self.value is None:\n",
        "            self.value = float(value)\n",
        "        else:\n",
        "            self.value = self.alpha * self.value + (1 - self.alpha) * float(value)\n",
        "        return self.value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gndmee31As4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 7\n",
        "num_wrkrs= 2\n",
        "train_dataset = CityScapesDataset(csv_file='train_local.csv')\n",
        "val_dataset = CityScapesDataset(csv_file='val_local.csv')\n",
        "test_dataset = CityScapesDataset(csv_file='test_local.csv')\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          num_workers=num_wrkrs,\n",
        "                          shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          num_workers=num_wrkrs,\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          num_workers=num_wrkrs,\n",
        "                          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxo9AEgcAs4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_loss(pred, target):\n",
        "    smooth = 1e-7\n",
        "    num = pred.size(0)\n",
        "    # print(pred.size())\n",
        "    # print(target.size())\n",
        "    m1 = pred.reshape(num, -1)  # Flatten\n",
        "    m2 = target.reshape(num, -1)  # Flatten\n",
        "    # print(m1.size())\n",
        "    intersection = (m1 * m2).sum()\n",
        "\n",
        "    return 1 - ((2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdU43gWpAs4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "        m.bias.data.zero_()\n",
        "epochs     = 100\n",
        "start_epoch = 30\n",
        "fcn_model = FCN_bak(n_class=34)\n",
        "# fcn_model.apply(init_weights)\n",
        "fcn_model.load_state_dict(torch.load('/content/drive/My Drive/CSE253/PA3/Dice/model_02_15_23_42.pt'))\n",
        "optimizer = optim.Adam(fcn_model.parameters(), lr = 1e-4, weight_decay= 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gipH8gimAs4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt = datetime.now().strftime(\"%m_%d_%H_%M\")\n",
        "output_fn = \"/content/drive/My Drive/CSE253/PA3/Dice/model_output_\" + dt + \".txt\"\n",
        "best_model_fn = \"/content/drive/My Drive/CSE253/PA3/Dice/best_model_\" + dt + \".pt\"\n",
        "model_fn = \"/content/drive/My Drive/CSE253/PA3/Dice/model_\" + dt + \".pt\"\n",
        "\n",
        "def print_info(out_str):\n",
        "    f = open(output_fn,\"a\")\n",
        "    print(out_str)\n",
        "    f.write(out_str)\n",
        "    f.close()\n",
        "\n",
        "# print_info(\"Started: %s\\nFrom a previously trained model which left off on start of epoch 9.\\n\" % datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "scrolled": false,
        "colab_type": "code",
        "outputId": "c819e482-8c87-4ef1-b2c5-3bb0d858fdce",
        "id": "hk1Q_oWZMkNP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "# use_gpu = False\n",
        "if use_gpu:\n",
        "    fcn_model = fcn_model.to(device)\n",
        "    print(\"GPU works\")\n",
        "    \n",
        "best_loss = float('inf')\n",
        "prev_loss = float('inf')\n",
        "loss_inc_cnt = 0\n",
        "stop_early = False\n",
        "\n",
        "def train():\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    print(\"Starting Training\")\n",
        "    trn_losses = MovingAverage() \n",
        "    trn_accs = MovingAverage() \n",
        "    trn_ious = MovingAverage() \n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        \n",
        "        ts = time.time()\n",
        "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            if use_gpu:\n",
        "                inputs = X.to(device)\n",
        "                labels_cat = Y.to(device)\n",
        "                labels_enc = tar.to(device)\n",
        "            else:\n",
        "                inputs, labels_cat, labels_enc = X, Y, tar\n",
        "\n",
        "            outputs = softmax(fcn_model(inputs))\n",
        "            # labels_enc = torch.nn.functional.one_hot(labels_cat,num_classes =34).permute(0,3,1,2)\n",
        "            # print(labels_enc.size())\n",
        "            # print(outputs.size())\n",
        "            \n",
        "            # print(outputs.requires_grad)\n",
        "            # output_labels = F.one_hot(softmax(outputs).argmax(dim=1),num_classes=34).float()\n",
        "            # output_labels = F.one_hot(fcn_model(inputs).argmax(dim=1),num_classes=34).float()\n",
        "            # output_labels.requires_grad = True\n",
        "            # print(output_labels.requires_grad)\n",
        "            loss = dice_loss(outputs, labels_enc)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss = loss.item()\n",
        "\n",
        "            output_labels = outputs.argmax(dim=1)\n",
        "\n",
        "            trn_losses.update(loss)\n",
        "            trn_accs.update(pixel_acc(output_labels, labels_cat))\n",
        "            trn_ious.update(np.nanmean(iou(output_labels, labels_cat)))\n",
        "\n",
        "            if iter % 10 == 0:\n",
        "                print_info(\"epoch{}, iter{}, loss: {} \\n\".format(epoch, iter, loss))\n",
        "\n",
        "        print_info(\"Finish epoch {}, time elapsed {} \\n\".format(epoch, time.time() - ts))\n",
        "\n",
        "        loss, acc, IoU = trn_losses.value, trn_accs.value, trn_ious.value\n",
        "\n",
        "        print_info(\"Training Check:\\tLoss: %f\\tAccuracy: %f\\tIoU: %f \\n\" % (loss, acc * 100, IoU))\n",
        "        \n",
        "        val(epoch)\n",
        "        if stop_early: return\n",
        "  \n",
        "def evaluate(data_loader, validation=False, verbose=False):\n",
        "\n",
        "    global best_loss\n",
        "    global prev_loss\n",
        "    global loss_inc_cnt\n",
        "    global stop_early\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        losses = []\n",
        "        accs = []\n",
        "        ious = []\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        ts = time.time()\n",
        "        print(\"Starting Evaluation\")\n",
        "        \n",
        "        for iter, (X, tar, Y) in enumerate(data_loader):\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs = X.to(device)\n",
        "                labels_cat = Y.to(device)\n",
        "                labels_enc = tar.to(device)\n",
        "            else:\n",
        "                inputs, labels_cat, labels_enc = X, Y, tar\n",
        "\n",
        "            outputs = softmax(fcn_model(inputs))\n",
        "            # labels_enc = torch.nn.functional.one_hot(labels_cat,num_classes =34).permute(0,3,1,2)\n",
        "            # output_labels = F.one_hot(outputs.argmax(dim=1),num_classes=34)\n",
        "\n",
        "            losses.append(dice_loss(outputs, labels_enc).item())\n",
        "\n",
        "            output_labels = outputs.argmax(dim=1)\n",
        "\n",
        "            accs.append(pixel_acc(output_labels, labels_cat))\n",
        "            \n",
        "            buffer = iou(output_labels, labels_cat)\n",
        "            ious.append(np.nanmean(buffer))\n",
        "            building_iou.append(buffer[building])\n",
        "            traffic_sign_iou.append(buffer[traffic_sign])\n",
        "            person_iou.append(buffer[person])\n",
        "            car_iou.append(buffer[car])\n",
        "            bicycle_iou.append(buffer[bicycle])\n",
        "        print(\"Finished evaluation. Time elapsed %f\" % (time.time() - ts))\n",
        "\n",
        "        # This probably should not be a straight average, but just doing this for now\n",
        "        loss = np.mean(losses)\n",
        "        acc = np.mean(accs)\n",
        "        IoU = np.mean(ious)\n",
        "        BIOU = np.mean(building_iou)\n",
        "        TIOU = np.mean(traffic_sign_iou)\n",
        "        PIOU = np.mean(person_iou)\n",
        "        CIOU = np.mean(car_iou)\n",
        "        BiIOU = np.mean(bicycle_iou)\n",
        "        if validation:\n",
        "            if best_loss > loss:\n",
        "                best_loss = loss\n",
        "                print_info(\"Best Loss: \" + str(best_loss) + \"\\n\")\n",
        "                torch.save(fcn_model.state_dict(), best_model_fn)\n",
        "            loss_inc_cnt = loss_inc_cnt + 1 if prev_loss < loss else 0\n",
        "            if loss_inc_cnt > 3: stop_early = True\n",
        "            torch.save(fcn_model.state_dict(), model_fn)\n",
        "        \n",
        "        return loss, acc, IoU, BIOU, TIOU, PIOU, CIOU, BiIOU\n",
        "\n",
        "\n",
        "def val(epoch):\n",
        "    # fcn_model.eval()\n",
        "    # Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
        "    # Make sure to include a softmax after the output from your model\n",
        "    loss, acc, IoU ,A,B,C,D,E= evaluate(val_loader, validation=True)\n",
        "    print_info(\"Validation Results: Loss: %f\\tAccuracy: %f\\tIoU: %f \\n building: %f\\t traffic:%f\\t person:%f\\t car:%f\\t bicycle:%f\\t\" % (loss, acc * 100, IoU, A,B,C,D,E))\n",
        "    if stop_early: print_info(\"Epoch %d:\\tStopping Early\" % (epoch))\n",
        "    \n",
        "def test():\n",
        "    print(' ')\n",
        "    # Complete this function - Calculate accuracy and IoU \n",
        "    # Make sure to include a softmax after the output from your model\n",
        "    loss, acc, IoU = evaluate(test_loader)\n",
        "    print_info(\"Test Results:\\tLoss: %f\\tAccuracy: %f\\tIoU: %f \\n\" % (loss, acc * 100, IoU))\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    # val(0)  # show the accuracy before training\n",
        "    # print_info(\"---------Above is accuracy before training.---------\\n\")\n",
        "    train()\n",
        "    # test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU works\n",
            "Starting Training\n",
            "epoch30, iter0, loss: 0.471845805644989 \n",
            "\n",
            "epoch30, iter10, loss: 0.48630237579345703 \n",
            "\n",
            "epoch30, iter20, loss: 0.5327383279800415 \n",
            "\n",
            "epoch30, iter30, loss: 0.4254082441329956 \n",
            "\n",
            "epoch30, iter40, loss: 0.5251901149749756 \n",
            "\n",
            "epoch30, iter50, loss: 0.5396333932876587 \n",
            "\n",
            "epoch30, iter60, loss: 0.49754029512405396 \n",
            "\n",
            "epoch30, iter70, loss: 0.5022299289703369 \n",
            "\n",
            "epoch30, iter80, loss: 0.471383273601532 \n",
            "\n",
            "epoch30, iter90, loss: 0.49218785762786865 \n",
            "\n",
            "epoch30, iter100, loss: 0.4511209726333618 \n",
            "\n",
            "epoch30, iter110, loss: 0.48105841875076294 \n",
            "\n",
            "epoch30, iter120, loss: 0.5135829448699951 \n",
            "\n",
            "epoch30, iter130, loss: 0.43207961320877075 \n",
            "\n",
            "epoch30, iter140, loss: 0.45331746339797974 \n",
            "\n",
            "epoch30, iter150, loss: 0.4256807565689087 \n",
            "\n",
            "epoch30, iter160, loss: 0.45807355642318726 \n",
            "\n",
            "epoch30, iter170, loss: 0.4973229765892029 \n",
            "\n",
            "epoch30, iter180, loss: 0.5460232496261597 \n",
            "\n",
            "epoch30, iter190, loss: 0.44363176822662354 \n",
            "\n",
            "epoch30, iter200, loss: 0.5729594230651855 \n",
            "\n",
            "epoch30, iter210, loss: 0.5303155183792114 \n",
            "\n",
            "epoch30, iter220, loss: 0.4946395754814148 \n",
            "\n",
            "epoch30, iter230, loss: 0.5114521980285645 \n",
            "\n",
            "epoch30, iter240, loss: 0.4459872841835022 \n",
            "\n",
            "epoch30, iter250, loss: 0.5343153476715088 \n",
            "\n",
            "epoch30, iter260, loss: 0.5692582130432129 \n",
            "\n",
            "epoch30, iter270, loss: 0.42280566692352295 \n",
            "\n",
            "epoch30, iter280, loss: 0.4817362427711487 \n",
            "\n",
            "epoch30, iter290, loss: 0.4501100778579712 \n",
            "\n",
            "epoch30, iter300, loss: 0.5203911066055298 \n",
            "\n",
            "epoch30, iter310, loss: 0.42979663610458374 \n",
            "\n",
            "epoch30, iter320, loss: 0.505119800567627 \n",
            "\n",
            "epoch30, iter330, loss: 0.5487631559371948 \n",
            "\n",
            "epoch30, iter340, loss: 0.532996654510498 \n",
            "\n",
            "epoch30, iter350, loss: 0.3914111256599426 \n",
            "\n",
            "epoch30, iter360, loss: 0.4858630895614624 \n",
            "\n",
            "epoch30, iter370, loss: 0.5292724370956421 \n",
            "\n",
            "epoch30, iter380, loss: 0.5142130255699158 \n",
            "\n",
            "epoch30, iter390, loss: 0.5615143775939941 \n",
            "\n",
            "epoch30, iter400, loss: 0.45383530855178833 \n",
            "\n",
            "epoch30, iter410, loss: 0.478720486164093 \n",
            "\n",
            "epoch30, iter420, loss: 0.507982075214386 \n",
            "\n",
            "Finish epoch 30, time elapsed 1425.8188350200653 \n",
            "\n",
            "Training Check:\tLoss: 0.490526\tAccuracy: 51.008214\tIoU: 0.179533 \n",
            "\n",
            "Starting Evaluation\n",
            "Finished evaluation. Time elapsed 288.064318\n",
            "Best Loss: 0.5001666007770432\n",
            "\n",
            "Validation Results: Loss: 0.500167\tAccuracy: 50.057721\tIoU: 0.175665 \n",
            "\n",
            "epoch31, iter0, loss: 0.47520971298217773 \n",
            "\n",
            "epoch31, iter10, loss: 0.4682326912879944 \n",
            "\n",
            "epoch31, iter20, loss: 0.43885278701782227 \n",
            "\n",
            "epoch31, iter30, loss: 0.4287737011909485 \n",
            "\n",
            "epoch31, iter40, loss: 0.4583243727684021 \n",
            "\n",
            "epoch31, iter50, loss: 0.4621111750602722 \n",
            "\n",
            "epoch31, iter60, loss: 0.5065709948539734 \n",
            "\n",
            "epoch31, iter70, loss: 0.4952254891395569 \n",
            "\n",
            "epoch31, iter80, loss: 0.5092828273773193 \n",
            "\n",
            "epoch31, iter90, loss: 0.4706360101699829 \n",
            "\n",
            "epoch31, iter100, loss: 0.5185509324073792 \n",
            "\n",
            "epoch31, iter110, loss: 0.5358341932296753 \n",
            "\n",
            "epoch31, iter120, loss: 0.5611732006072998 \n",
            "\n",
            "epoch31, iter130, loss: 0.4445001482963562 \n",
            "\n",
            "epoch31, iter140, loss: 0.5374454259872437 \n",
            "\n",
            "epoch31, iter150, loss: 0.4787871241569519 \n",
            "\n",
            "epoch31, iter160, loss: 0.4940173029899597 \n",
            "\n",
            "epoch31, iter170, loss: 0.5271763801574707 \n",
            "\n",
            "epoch31, iter180, loss: 0.47355639934539795 \n",
            "\n",
            "epoch31, iter190, loss: 0.4090242385864258 \n",
            "\n",
            "epoch31, iter200, loss: 0.5209090113639832 \n",
            "\n",
            "epoch31, iter210, loss: 0.4992606043815613 \n",
            "\n",
            "epoch31, iter220, loss: 0.4351131319999695 \n",
            "\n",
            "epoch31, iter230, loss: 0.512373685836792 \n",
            "\n",
            "epoch31, iter240, loss: 0.4653211832046509 \n",
            "\n",
            "epoch31, iter250, loss: 0.4558259844779968 \n",
            "\n",
            "epoch31, iter260, loss: 0.48858100175857544 \n",
            "\n",
            "epoch31, iter270, loss: 0.6334215998649597 \n",
            "\n",
            "epoch31, iter280, loss: 0.5109738111495972 \n",
            "\n",
            "epoch31, iter290, loss: 0.510089635848999 \n",
            "\n",
            "epoch31, iter300, loss: 0.5382462739944458 \n",
            "\n",
            "epoch31, iter310, loss: 0.42940419912338257 \n",
            "\n",
            "epoch31, iter320, loss: 0.49037569761276245 \n",
            "\n",
            "epoch31, iter330, loss: 0.4768701195716858 \n",
            "\n",
            "epoch31, iter340, loss: 0.45616596937179565 \n",
            "\n",
            "epoch31, iter350, loss: 0.4591464400291443 \n",
            "\n",
            "epoch31, iter360, loss: 0.45183414220809937 \n",
            "\n",
            "epoch31, iter370, loss: 0.5061293244361877 \n",
            "\n",
            "epoch31, iter380, loss: 0.47220855951309204 \n",
            "\n",
            "epoch31, iter390, loss: 0.557532787322998 \n",
            "\n",
            "epoch31, iter400, loss: 0.5243142247200012 \n",
            "\n",
            "epoch31, iter410, loss: 0.549997091293335 \n",
            "\n",
            "epoch31, iter420, loss: 0.46797430515289307 \n",
            "\n",
            "Finish epoch 31, time elapsed 1452.919246673584 \n",
            "\n",
            "Training Check:\tLoss: 0.489119\tAccuracy: 51.165957\tIoU: 0.179797 \n",
            "\n",
            "Starting Evaluation\n",
            "Finished evaluation. Time elapsed 287.585336\n",
            "Validation Results: Loss: 0.501280\tAccuracy: 49.955286\tIoU: 0.174945 \n",
            "\n",
            "epoch32, iter0, loss: 0.42165958881378174 \n",
            "\n",
            "epoch32, iter10, loss: 0.4453633427619934 \n",
            "\n",
            "epoch32, iter20, loss: 0.36565685272216797 \n",
            "\n",
            "epoch32, iter30, loss: 0.5105555653572083 \n",
            "\n",
            "epoch32, iter40, loss: 0.42835837602615356 \n",
            "\n",
            "epoch32, iter50, loss: 0.44170671701431274 \n",
            "\n",
            "epoch32, iter60, loss: 0.5368121862411499 \n",
            "\n",
            "epoch32, iter70, loss: 0.5077462196350098 \n",
            "\n",
            "epoch32, iter80, loss: 0.49714094400405884 \n",
            "\n",
            "epoch32, iter90, loss: 0.551571786403656 \n",
            "\n",
            "epoch32, iter100, loss: 0.5356361269950867 \n",
            "\n",
            "epoch32, iter110, loss: 0.4807280898094177 \n",
            "\n",
            "epoch32, iter120, loss: 0.5027602910995483 \n",
            "\n",
            "epoch32, iter130, loss: 0.5353147983551025 \n",
            "\n",
            "epoch32, iter140, loss: 0.4963998794555664 \n",
            "\n",
            "epoch32, iter150, loss: 0.504395604133606 \n",
            "\n",
            "epoch32, iter160, loss: 0.457133948802948 \n",
            "\n",
            "epoch32, iter170, loss: 0.5330806970596313 \n",
            "\n",
            "epoch32, iter180, loss: 0.5054149627685547 \n",
            "\n",
            "epoch32, iter190, loss: 0.5655770301818848 \n",
            "\n",
            "epoch32, iter200, loss: 0.39432036876678467 \n",
            "\n",
            "epoch32, iter210, loss: 0.4369911551475525 \n",
            "\n",
            "epoch32, iter220, loss: 0.40067052841186523 \n",
            "\n",
            "epoch32, iter230, loss: 0.41634541749954224 \n",
            "\n",
            "epoch32, iter240, loss: 0.48795801401138306 \n",
            "\n",
            "epoch32, iter250, loss: 0.4903193712234497 \n",
            "\n",
            "epoch32, iter260, loss: 0.4360455274581909 \n",
            "\n",
            "epoch32, iter270, loss: 0.5358966588973999 \n",
            "\n",
            "epoch32, iter280, loss: 0.4156545400619507 \n",
            "\n",
            "epoch32, iter290, loss: 0.487237811088562 \n",
            "\n",
            "epoch32, iter300, loss: 0.5098015666007996 \n",
            "\n",
            "epoch32, iter310, loss: 0.49573153257369995 \n",
            "\n",
            "epoch32, iter320, loss: 0.5886019468307495 \n",
            "\n",
            "epoch32, iter330, loss: 0.5067878365516663 \n",
            "\n",
            "epoch32, iter340, loss: 0.5918881297111511 \n",
            "\n",
            "epoch32, iter350, loss: 0.5179848670959473 \n",
            "\n",
            "epoch32, iter360, loss: 0.4673527479171753 \n",
            "\n",
            "epoch32, iter370, loss: 0.5229095220565796 \n",
            "\n",
            "epoch32, iter380, loss: 0.5209565162658691 \n",
            "\n",
            "epoch32, iter390, loss: 0.4531450867652893 \n",
            "\n",
            "epoch32, iter400, loss: 0.44830411672592163 \n",
            "\n",
            "epoch32, iter410, loss: 0.5106666088104248 \n",
            "\n",
            "epoch32, iter420, loss: 0.5685925483703613 \n",
            "\n",
            "Finish epoch 32, time elapsed 1478.3541793823242 \n",
            "\n",
            "Training Check:\tLoss: 0.492143\tAccuracy: 50.874872\tIoU: 0.178950 \n",
            "\n",
            "Starting Evaluation\n",
            "Finished evaluation. Time elapsed 291.340919\n",
            "Validation Results: Loss: 0.501736\tAccuracy: 49.924588\tIoU: 0.174865 \n",
            "\n",
            "epoch33, iter0, loss: 0.4106476902961731 \n",
            "\n",
            "epoch33, iter10, loss: 0.4271312952041626 \n",
            "\n",
            "epoch33, iter20, loss: 0.5355527400970459 \n",
            "\n",
            "epoch33, iter30, loss: 0.44095176458358765 \n",
            "\n",
            "epoch33, iter40, loss: 0.5108275413513184 \n",
            "\n",
            "epoch33, iter50, loss: 0.44306057691574097 \n",
            "\n",
            "epoch33, iter60, loss: 0.46188998222351074 \n",
            "\n",
            "epoch33, iter70, loss: 0.48620855808258057 \n",
            "\n",
            "epoch33, iter80, loss: 0.5025277137756348 \n",
            "\n",
            "epoch33, iter90, loss: 0.4558008313179016 \n",
            "\n",
            "epoch33, iter100, loss: 0.45203697681427 \n",
            "\n",
            "epoch33, iter110, loss: 0.5078191757202148 \n",
            "\n",
            "epoch33, iter120, loss: 0.46862471103668213 \n",
            "\n",
            "epoch33, iter130, loss: 0.47131264209747314 \n",
            "\n",
            "epoch33, iter140, loss: 0.4776265621185303 \n",
            "\n",
            "epoch33, iter150, loss: 0.43659746646881104 \n",
            "\n",
            "epoch33, iter160, loss: 0.5534753799438477 \n",
            "\n",
            "epoch33, iter170, loss: 0.4908323884010315 \n",
            "\n",
            "epoch33, iter180, loss: 0.46527689695358276 \n",
            "\n",
            "epoch33, iter190, loss: 0.4933174252510071 \n",
            "\n",
            "epoch33, iter200, loss: 0.4230004549026489 \n",
            "\n",
            "epoch33, iter210, loss: 0.5319697856903076 \n",
            "\n",
            "epoch33, iter220, loss: 0.5665879249572754 \n",
            "\n",
            "epoch33, iter230, loss: 0.5242980122566223 \n",
            "\n",
            "epoch33, iter240, loss: 0.43520814180374146 \n",
            "\n",
            "epoch33, iter250, loss: 0.497946560382843 \n",
            "\n",
            "epoch33, iter260, loss: 0.5067803263664246 \n",
            "\n",
            "epoch33, iter270, loss: 0.512252926826477 \n",
            "\n",
            "epoch33, iter280, loss: 0.48923879861831665 \n",
            "\n",
            "epoch33, iter290, loss: 0.43779319524765015 \n",
            "\n",
            "epoch33, iter300, loss: 0.5196701884269714 \n",
            "\n",
            "epoch33, iter310, loss: 0.4461812376976013 \n",
            "\n",
            "epoch33, iter320, loss: 0.42902690172195435 \n",
            "\n",
            "epoch33, iter330, loss: 0.5129718780517578 \n",
            "\n",
            "epoch33, iter340, loss: 0.5352334380149841 \n",
            "\n",
            "epoch33, iter350, loss: 0.5309925079345703 \n",
            "\n",
            "epoch33, iter360, loss: 0.5197610855102539 \n",
            "\n",
            "epoch33, iter370, loss: 0.44530099630355835 \n",
            "\n",
            "epoch33, iter380, loss: 0.4954138994216919 \n",
            "\n",
            "epoch33, iter390, loss: 0.5511276721954346 \n",
            "\n",
            "epoch33, iter400, loss: 0.4212172031402588 \n",
            "\n",
            "epoch33, iter410, loss: 0.45892852544784546 \n",
            "\n",
            "epoch33, iter420, loss: 0.5195990800857544 \n",
            "\n",
            "Finish epoch 33, time elapsed 1496.6474242210388 \n",
            "\n",
            "Training Check:\tLoss: 0.496067\tAccuracy: 50.496638\tIoU: 0.177434 \n",
            "\n",
            "Starting Evaluation\n",
            "Finished evaluation. Time elapsed 295.309517\n",
            "Validation Results: Loss: 0.503462\tAccuracy: 49.767648\tIoU: 0.173825 \n",
            "\n",
            "epoch34, iter0, loss: 0.5095556974411011 \n",
            "\n",
            "epoch34, iter10, loss: 0.47192156314849854 \n",
            "\n",
            "epoch34, iter20, loss: 0.44234418869018555 \n",
            "\n",
            "epoch34, iter30, loss: 0.5518238544464111 \n",
            "\n",
            "epoch34, iter40, loss: 0.5308268666267395 \n",
            "\n",
            "epoch34, iter50, loss: 0.4784137010574341 \n",
            "\n",
            "epoch34, iter60, loss: 0.5168125629425049 \n",
            "\n",
            "epoch34, iter70, loss: 0.5245219469070435 \n",
            "\n",
            "epoch34, iter80, loss: 0.4965190291404724 \n",
            "\n",
            "epoch34, iter90, loss: 0.5432696342468262 \n",
            "\n",
            "epoch34, iter100, loss: 0.5024269819259644 \n",
            "\n",
            "epoch34, iter110, loss: 0.42391252517700195 \n",
            "\n",
            "epoch34, iter120, loss: 0.5403298735618591 \n",
            "\n",
            "epoch34, iter130, loss: 0.47715461254119873 \n",
            "\n",
            "epoch34, iter140, loss: 0.5276780128479004 \n",
            "\n",
            "epoch34, iter150, loss: 0.4923878312110901 \n",
            "\n",
            "epoch34, iter160, loss: 0.5021913051605225 \n",
            "\n",
            "epoch34, iter170, loss: 0.4413423538208008 \n",
            "\n",
            "epoch34, iter180, loss: 0.5515670776367188 \n",
            "\n",
            "epoch34, iter190, loss: 0.5412724018096924 \n",
            "\n",
            "epoch34, iter200, loss: 0.5206024646759033 \n",
            "\n",
            "epoch34, iter210, loss: 0.5237456560134888 \n",
            "\n",
            "epoch34, iter220, loss: 0.49070823192596436 \n",
            "\n",
            "epoch34, iter230, loss: 0.48486465215682983 \n",
            "\n",
            "epoch34, iter240, loss: 0.5853712558746338 \n",
            "\n",
            "epoch34, iter250, loss: 0.4933850169181824 \n",
            "\n",
            "epoch34, iter260, loss: 0.48009276390075684 \n",
            "\n",
            "epoch34, iter270, loss: 0.47498244047164917 \n",
            "\n",
            "epoch34, iter280, loss: 0.4743701219558716 \n",
            "\n",
            "epoch34, iter290, loss: 0.5157649517059326 \n",
            "\n",
            "epoch34, iter300, loss: 0.52201247215271 \n",
            "\n",
            "epoch34, iter310, loss: 0.479079008102417 \n",
            "\n",
            "epoch34, iter320, loss: 0.46601027250289917 \n",
            "\n",
            "epoch34, iter330, loss: 0.5374263525009155 \n",
            "\n",
            "epoch34, iter340, loss: 0.5068297982215881 \n",
            "\n",
            "epoch34, iter350, loss: 0.5003964304924011 \n",
            "\n",
            "epoch34, iter360, loss: 0.43366116285324097 \n",
            "\n",
            "epoch34, iter370, loss: 0.3324301838874817 \n",
            "\n",
            "epoch34, iter380, loss: 0.4908459186553955 \n",
            "\n",
            "epoch34, iter390, loss: 0.49504023790359497 \n",
            "\n",
            "epoch34, iter400, loss: 0.5344483852386475 \n",
            "\n",
            "epoch34, iter410, loss: 0.4526747465133667 \n",
            "\n",
            "epoch34, iter420, loss: 0.4949440360069275 \n",
            "\n",
            "Finish epoch 34, time elapsed 1538.3110721111298 \n",
            "\n",
            "Training Check:\tLoss: 0.493520\tAccuracy: 50.764188\tIoU: 0.177876 \n",
            "\n",
            "Starting Evaluation\n",
            "Finished evaluation. Time elapsed 300.371564\n",
            "Validation Results: Loss: 0.506207\tAccuracy: 49.498348\tIoU: 0.172965 \n",
            "\n",
            "epoch35, iter0, loss: 0.4824976325035095 \n",
            "\n",
            "epoch35, iter10, loss: 0.4896038770675659 \n",
            "\n",
            "epoch35, iter20, loss: 0.535327672958374 \n",
            "\n",
            "epoch35, iter30, loss: 0.47955000400543213 \n",
            "\n",
            "epoch35, iter40, loss: 0.4387044310569763 \n",
            "\n",
            "epoch35, iter50, loss: 0.4457288980484009 \n",
            "\n",
            "epoch35, iter60, loss: 0.5038892030715942 \n",
            "\n",
            "epoch35, iter70, loss: 0.45771992206573486 \n",
            "\n",
            "epoch35, iter80, loss: 0.5724008083343506 \n",
            "\n",
            "epoch35, iter90, loss: 0.5339560508728027 \n",
            "\n",
            "epoch35, iter100, loss: 0.45490866899490356 \n",
            "\n",
            "epoch35, iter110, loss: 0.39329880475997925 \n",
            "\n",
            "epoch35, iter120, loss: 0.47969257831573486 \n",
            "\n",
            "epoch35, iter130, loss: 0.542107105255127 \n",
            "\n",
            "epoch35, iter140, loss: 0.47072428464889526 \n",
            "\n",
            "epoch35, iter150, loss: 0.4486004710197449 \n",
            "\n",
            "epoch35, iter160, loss: 0.5564631223678589 \n",
            "\n",
            "epoch35, iter170, loss: 0.48033422231674194 \n",
            "\n",
            "epoch35, iter180, loss: 0.5204734802246094 \n",
            "\n",
            "epoch35, iter190, loss: 0.46481579542160034 \n",
            "\n",
            "epoch35, iter200, loss: 0.4346507787704468 \n",
            "\n",
            "epoch35, iter210, loss: 0.4926658272743225 \n",
            "\n",
            "epoch35, iter220, loss: 0.5808313488960266 \n",
            "\n",
            "epoch35, iter230, loss: 0.45843613147735596 \n",
            "\n",
            "epoch35, iter240, loss: 0.44329047203063965 \n",
            "\n",
            "epoch35, iter250, loss: 0.48190242052078247 \n",
            "\n",
            "epoch35, iter260, loss: 0.48349612951278687 \n",
            "\n",
            "epoch35, iter270, loss: 0.49871695041656494 \n",
            "\n",
            "epoch35, iter280, loss: 0.49359405040740967 \n",
            "\n",
            "epoch35, iter290, loss: 0.511375904083252 \n",
            "\n",
            "epoch35, iter300, loss: 0.6020111441612244 \n",
            "\n",
            "epoch35, iter310, loss: 0.4981096386909485 \n",
            "\n",
            "epoch35, iter320, loss: 0.5155214071273804 \n",
            "\n",
            "epoch35, iter330, loss: 0.4347043037414551 \n",
            "\n",
            "epoch35, iter340, loss: 0.44456690549850464 \n",
            "\n",
            "epoch35, iter350, loss: 0.4308586120605469 \n",
            "\n",
            "epoch35, iter360, loss: 0.4913097023963928 \n",
            "\n",
            "epoch35, iter370, loss: 0.5214370489120483 \n",
            "\n",
            "epoch35, iter380, loss: 0.46758145093917847 \n",
            "\n",
            "epoch35, iter390, loss: 0.48973560333251953 \n",
            "\n",
            "epoch35, iter400, loss: 0.5605476498603821 \n",
            "\n",
            "epoch35, iter410, loss: 0.5043045878410339 \n",
            "\n",
            "epoch35, iter420, loss: 0.5377312898635864 \n",
            "\n",
            "Finish epoch 35, time elapsed 1569.8901116847992 \n",
            "\n",
            "Training Check:\tLoss: 0.499344\tAccuracy: 50.192552\tIoU: 0.175208 \n",
            "\n",
            "Starting Evaluation\n",
            "Finished evaluation. Time elapsed 299.600978\n",
            "Validation Results: Loss: 0.508963\tAccuracy: 49.240005\tIoU: 0.172041 \n",
            "\n",
            "epoch36, iter0, loss: 0.4594077467918396 \n",
            "\n",
            "epoch36, iter10, loss: 0.5865347385406494 \n",
            "\n",
            "epoch36, iter20, loss: 0.4353487491607666 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}