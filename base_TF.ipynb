{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "base_TF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BLvzuas7mvfV"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import utils\n",
        "from dataloader_resize import *\n",
        "from utils import *\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "78cBQZoWc6_P"
      },
      "outputs": [],
      "source": [
        "class AverageBase(object):\n",
        "    \n",
        "    def __init__(self, value=0):\n",
        "        self.value = float(value) if value is not None else None\n",
        "       \n",
        "    def __str__(self):\n",
        "        return str(round(self.value, 4))\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.value\n",
        "    \n",
        "    def __format__(self, fmt):\n",
        "        return self.value.__format__(fmt)\n",
        "    \n",
        "    def __float__(self):\n",
        "        return self.value\n",
        "    \n",
        "\n",
        "class RunningAverage(AverageBase):\n",
        "    \"\"\"\n",
        "    Keeps track of a cumulative moving average (CMA).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, value=0, count=0):\n",
        "        super(RunningAverage, self).__init__(value)\n",
        "        self.count = count\n",
        "        \n",
        "    def update(self, value):\n",
        "        self.value = (self.value * self.count + float(value))\n",
        "        self.count += 1\n",
        "        self.value /= self.count\n",
        "        return self.value\n",
        "\n",
        "\n",
        "class MovingAverage(AverageBase):\n",
        "    \"\"\"\n",
        "    An exponentially decaying moving average (EMA).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, alpha=0.99):\n",
        "        super(MovingAverage, self).__init__(None)\n",
        "        self.alpha = alpha\n",
        "        \n",
        "    def update(self, value):\n",
        "        if self.value is None:\n",
        "            self.value = float(value)\n",
        "        else:\n",
        "            self.value = self.alpha * self.value + (1 - self.alpha) * float(value)\n",
        "        return self.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rtW24hrg2B2h"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/My Drive/CSE253/PA3/Base_TL/'\n",
        "dt = datetime.now().strftime(\"%m_%d_%H_%M\")\n",
        "output_fn = path + \"model_output_\" + dt + \".txt\"\n",
        "best_model_fn = path + \"best_model_\" + dt + \".pt\"\n",
        "model_fn = path + \"model_\" + dt + \".pt\"\n",
        "\n",
        "def print_info(out_str):\n",
        "    f = open(output_fn,\"a\")\n",
        "    print(out_str)\n",
        "    f.write(out_str)\n",
        "    f.close()\n",
        "\n",
        "# print_info(\"Started: %s\\nFrom a previously trained model which left off on start of epoch 9.\\n\" % datetime.now())\n",
        "print_info(\"Started: %s\\n\" % datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Q7pigYMMSnC1"
      },
      "outputs": [],
      "source": [
        "class FCN_TL(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_class):\n",
        "        super(FCN_TL, self).__init__()\n",
        "        self.n_class = n_class\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        # Parameters of newly constructed modules have requires_grad=True by default\n",
        "        self.model_conv = torchvision.models.resnet50(pretrained=True)\n",
        "        self.in_ftrs = 1000 \n",
        "        for param in self.model_conv.parameters():\n",
        "          param.requires_grad = False\n",
        "        \n",
        "        self.conv1   = nn.Conv2d(self.in_ftrs, 512, kernel_size=2, stride=1, padding=1, dilation=1)\n",
        "        self.cbnd1   = nn.BatchNorm2d(512)\n",
        "        self.conv2   = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=2, dilation=1)\n",
        "        self.cbnd2   = nn.BatchNorm2d(256)\n",
        "        self.deconv1 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(128)\n",
        "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(64)\n",
        "        self.deconv3 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(32)\n",
        "        self.deconv4 = nn.ConvTranspose2d(32, 16, kernel_size=5, stride=4, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(16)\n",
        "        self.deconv5 = nn.ConvTranspose2d(16, 8, kernel_size=5, stride=4, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(8)\n",
        "        self.deconv6 = nn.ConvTranspose2d(8, 4, kernel_size=(3,5), stride=(2,4), padding=1, dilation=1, output_padding=1)\n",
        "        self.bn6     = nn.BatchNorm2d(4)\n",
        "        self.classifier = nn.Conv2d(4,self.n_class, kernel_size=1, stride=1, padding=0, dilation=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        z = self.model_conv(x).unsqueeze_(-1).unsqueeze_(-1)\n",
        "        z = self.cbnd1(self.relu(self.conv1(z)))\n",
        "        z = self.cbnd2(self.relu(self.conv2(z)))\n",
        "        z = self.bn1(self.relu(self.deconv1(z)))\n",
        "        z = self.bn2(self.relu(self.deconv2(z)))\n",
        "        z = self.bn3(self.relu(self.deconv3(z)))\n",
        "        z = self.bn4(self.relu(self.deconv4(z)))\n",
        "        z = self.bn5(self.relu(self.deconv5(z)))\n",
        "        z = self.bn6(self.relu(self.deconv6(z)))\n",
        "        \n",
        "        out_decoder = self.classifier(z)                  \n",
        "\n",
        "        return out_decoder  # size=(N, n_class, x.H/1, x.W/1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nu7sqQI8SnDC",
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "def print_GPU_stats():\n",
        "    print(\"total GPU Mem: \", torch.cuda.get_device_properties(device).total_memory)\n",
        "    print(\"total GPU Cached: \", torch.cuda.memory_cached(device))\n",
        "    print(\"total GPU Allocated: \", torch.cuda.memory_allocated(device))\n",
        "    print(\"Available GB: \", (torch.cuda.get_device_properties(device).total_memory - torch.cuda.memory_allocated(device))/(10**9))\n",
        "print_GPU_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OGZauIrfTJe9"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "num_wrkrs = 4\n",
        "train_dataset = CityScapesDataset(csv_file='train_local.csv')\n",
        "val_dataset = CityScapesDataset(csv_file='val_local.csv')\n",
        "test_dataset = CityScapesDataset(csv_file='test_local.csv')\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          num_workers=num_wrkrs,\n",
        "                          shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          num_workers=num_wrkrs,\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          num_workers=num_wrkrs,\n",
        "                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UCBCrM8Tmvga"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "        m.bias.data.zero_()\n",
        "\n",
        "\n",
        "\n",
        "fcn_model = FCN_TL(n_class=34)\n",
        "fcn_model.apply(init_weights)\n",
        "fcn_model = fcn_model.to(device)\n",
        "\n",
        "\n",
        "epochs     = 100\n",
        "start_epoch = 1\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# fcn_model.load_state_dict(torch.load(path + 'model_02_13_08_47.pt'))\n",
        "optimizer = optim.Adam(fcn_model.parameters(), lr=5e-4, weight_decay=1e-3)\n",
        "# optimizer = optim.SGD(model_conv.parameters(), lr=5e-4, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "g27N81T6SnDa",
        "pycharm": {
          "is_executing": false
        },
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "# use_gpu = False\n",
        "if use_gpu:\n",
        "    fcn_model = fcn_model.to(device)\n",
        "    \n",
        "best_loss = float('inf')\n",
        "prev_loss = float('inf')\n",
        "loss_inc_cnt = 0\n",
        "stop_early = False\n",
        "\n",
        "def train():\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    print(\"Starting Training\")\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        trn_losses = MovingAverage()\n",
        "        trn_accs = MovingAverage()\n",
        "        trn_ious = MovingAverage()\n",
        "        ts = time.time()\n",
        "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs = X.to(device)\n",
        "                labels_cat = Y.to(device)\n",
        "            else:\n",
        "                inputs, labels_cat, labels_enc = X, Y, tar\n",
        "            \n",
        "            outputs = softmax(fcn_model(inputs))\n",
        "            loss = criterion(outputs, labels_cat)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss = loss.item()\n",
        "\n",
        "            output_labels = outputs.argmax(dim=1)\n",
        "\n",
        "            trn_losses.update(loss)\n",
        "            trn_accs.update(pixel_acc(output_labels, labels_cat))\n",
        "            trn_ious.update(np.nanmean(iou(output_labels, labels_cat)))\n",
        "            \n",
        "            if iter % 10 == 0:\n",
        "                print_info(\"epoch{}, iter{}, loss: {} \\n\".format(epoch, iter, loss))\n",
        "                \n",
        "        \n",
        "        print_info(\"Finish epoch {}, time elapsed {} \\n\".format(epoch, time.time() - ts))\n",
        "    \n",
        "        loss, acc, IoU = trn_losses.value, trn_accs.value, trn_ious.value \n",
        "\n",
        "        print_info(\"Training Check:\\tLoss: %f\\tAccuracy: %f\\tIoU: %f \\n\" % (loss, acc * 100, IoU))\n",
        "        \n",
        "        val(epoch)\n",
        "        if stop_early: return\n",
        "\n",
        "def evaluate(data_loader, validation=False, verbose=False):\n",
        "\n",
        "    global best_loss\n",
        "    global prev_loss\n",
        "    global loss_inc_cnt\n",
        "    global stop_early\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        losses = RunningAverage()\n",
        "        accs = RunningAverage()\n",
        "        ious = RunningAverage()\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        ts = time.time()\n",
        "        print(\"Starting Evaluation\")\n",
        "        \n",
        "        for iter, (X, tar, Y) in enumerate(data_loader):\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs = X.to(device)\n",
        "                labels_cat = Y.to(device)\n",
        "            else:\n",
        "                inputs, labels_cat, labels_enc = X, Y, tar\n",
        "\n",
        "            outputs = softmax(fcn_model(inputs))\n",
        "\n",
        "            output_labels = outputs.argmax(dim=1)\n",
        "\n",
        "            losses.update(criterion(outputs, labels_cat).item())\n",
        "\n",
        "            accs.update(pixel_acc(output_labels, labels_cat))\n",
        "\n",
        "            ious.update(np.nanmean(iou(output_labels, labels_cat)))\n",
        "\n",
        "        print(\"Finished evaluation. Time elapsed %f\" % (time.time() - ts))\n",
        "\n",
        "        # This probably should not be a straight average, but just doing this for now\n",
        "        loss = losses.value \n",
        "        acc = accs.value \n",
        "        IoU = ious.value \n",
        "        \n",
        "        if validation:\n",
        "            if best_loss > loss:\n",
        "                best_loss = loss\n",
        "                print_info(\"Best Loss: \" + str(best_loss) + \"\\n\")\n",
        "                torch.save(fcn_model.state_dict(), best_model_fn)\n",
        "            loss_inc_cnt = loss_inc_cnt + 1 if prev_loss < loss else 0\n",
        "            if loss_inc_cnt > 3: stop_early = True\n",
        "            torch.save(fcn_model.state_dict(), model_fn)\n",
        "        \n",
        "        return loss, acc, IoU\n",
        "\n",
        "def val(epoch):\n",
        "    # fcn_model.eval()\n",
        "    # Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
        "    # Make sure to include a softmax after the output from your model\n",
        "    loss, acc, IoU = evaluate(val_loader, validation=True)\n",
        "    print_info(\"Validation Results: Loss: %f\\tAccuracy: %f\\tIoU: %f \\n\" % (loss, acc * 100, IoU))\n",
        "    if stop_early: print_info(\"Epoch %d:\\tStopping Early\" % (epoch))\n",
        "    \n",
        "def test():\n",
        "    print(' ')\n",
        "    # Complete this function - Calculate accuracy and IoU \n",
        "    # Make sure to include a softmax after the output from your model\n",
        "    loss, acc, IoU = evaluate(test_loader)\n",
        "    print_info(\"Test Results:\\tLoss: %f\\tAccuracy: %f\\tIoU: %f \\n\" % (loss, acc * 100, IoU))\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    # val(0)  # show the accuracy before training\n",
        "    # print_info(\"---------Above is accuracy before training.---------\\n\")\n",
        "    train()\n",
        "    test()"
      ]
    }
  ]
}